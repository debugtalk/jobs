# 大模型安全研究员-TikTok隐私创新实验室-筋斗云人才计划

**ID**: 7506101941932640519
**Code**: A101610
**Location**: 北京
**Category**: 算法
**Type**: 正式

## 职位描述

### 团队介绍
隐私创新实验室，致力于探索数据隐私安全领域的前沿技术和理论，为业务高速发展提供洞悉行业趋势的技术咨询和创新性的技术解决方案。隐私创新实验室在数据安全领域拥有长期愿景与决心，研究方向覆盖数字主权、合规智能、大模型个人隐私数据保护等。在日益趋严的隐私合规监管的历史时刻，多极化的数字主权意识逐步觉醒，我们更需要融合学术界和产业界的经验智慧，引入前沿技术和理论，为承载海量用户和海量数据的互联网业务提供高效完备的数据隐私安全保障，突破合规瓶颈，支持业务持续突破创新。
课题背景：随着生成式人工智能技术的持续演进，通用大模型正从模型能力的探索阶段迈入面向实际场景落地的“下半场”。在此阶段，产业界更关注如何将大模型技术与具体业务深度融合，释放其在智能生成、交互理解、决策支持等方面的潜能。这一过程面临着对多样场景、专业领域知识、数据合规性与部署可控性等更高要求。
尤其在特定行业/专业场景（specific domain）中，大模型需要既保留其通过大规模预训练获得的通用能力，又要通过高效适配，实现对领域知识的精准理解与表达。同时，随着AI系统进入金融、医疗、政务、广告等对隐私与安全要求极高的行业，如何在保证隐私保护、数据安全、合规使用的前提下，实现大模型的定制化能力增强，已成为GenAI规模化部署的关键瓶颈之一。
课题挑战：

### 实习要求


### 核心工作
1、通用性与专用性能力的动态平衡
大模型在预训练阶段形成了强大的通用语言理解与生成能力，但在特定业务领域往往存在“泛化过强、聚焦不足”的问题。如何在不破坏已有能力的前提下，安全地注入专业知识，是模型微调、提示调优（prompt tuning）与指令学习（instruction tuning）方法的核心挑战。
2、隐私保护与数据适配的双重目标冲突
为提升大模型在行业应用中的性能，往往需要大量高质量的专域数据，但这些数据常常涉及用户隐私、敏感属性或业务机密。如何设计隐私增强学习方法（如差分隐私训练、联邦学习、加密推理等），既保证模型性能，又符合法规与伦理要求，是一大技术难点。
3、安全鲁棒性与生成可控性的工程化落地
面对复杂的生成场景，模型需具备防止幻觉（hallucination）、规避敏感输出、抗提示注入（prompt injection）等安全能力，进一步需要构建可解释、可监控、可调试的生成控制机制，实现合规、安全、可审计的产品部署。
4、跨模态与多任务的任务迁移能力
在具体应用中，任务往往呈现多样性和复杂性（如结构化问答、多模态生成、长上下文对话等），大模型需要具备从有限监督信号中高效迁移能力，这要求在架构设计与训练范式上持续创新。

## 职位要求
1、获得博士学位，人工智能、计算机、数学相关专业优先；
2、有扎实的机器学习，大模型，Reinforcement Learning基础，在ICML/NeurIPS/ICLR等顶级会议上发表论文者优先；
3、优秀的代码能力、数据结构和基础算法功底，熟练C/C++或Python，ACM/ICPC、NOI/IOI、Top Coder、Kaggle等比赛获奖者优先；
4、出色的问题分析和解决能力，能深入解决大模型训练和应用存在的问题，有自主探索解决方案的能力；
5、良好的沟通协作能力，卓越的探索能力，能和团队一起探索新技术，推进技术进步。
