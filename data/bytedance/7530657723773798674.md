# 高性能计算研究员-Data语音

**ID**: 7530657723773798674
**Code**: A88578A
**Location**: 杭州
**Category**: 基础架构
**Type**: 正式

## 职位描述

### 团队介绍
Data语音团队致力于语音/音频/音乐相关的AI核心技术研发和产品创新。部门支撑音频和多模态内容从生产、编辑到消费的全流程，赋能内容创作和互动，并以中台形式支持集团多个业务，提供业界前沿的技术能力与解决方案。

### 实习要求


### 核心工作
1、负责构建新一代大模型推理引擎，优化多模态语音理解/语音生成等多模态生成大模型在GPU集群上的推理性能，实现低延迟、高吞吐的工业级部署；
2、主导模型推理性能优化，涵盖CUDA/Triton算子开发、vLLM/SGLang框架升级、分布式推理策略优化、量化/稀疏化等模型Efficiency加速优化等；
3、研发GPU推理加速技术栈，考虑最佳分布式通算结合方案，PCIe通信与高并发推理架构；
4、负责高性能方案前瞻性建设，构建基于C++/Python研发的高性能推理系统；
5、与上下游部门深度合作，分析性能瓶颈，通过软硬结合提升模型训推效率，优化和部署语音大模型，支持AI工具链和技术生态建设，推动字节跳动AI关键业务发展；
6、负责语音多模态场景下高性能推理系统的开发，支撑各业务场景下的性能优化需求并推动业务落地。

## 职位要求
1、2026届获得硕士及以上学位，人工智能、计算机、电子、信息、通信、自动化、软件等相关专业优先；
2、精通Python，熟悉C++特性，具备高性能代码开发能力和相关经验；
3、至少具备以下一个领域经验：GPU编程（CUDA/Triton/AscendC/TileLang开发）、模型量化/稀疏化/蒸馏、基于vLLM的框架研发，并行计算的通算结合（多卡/多机推理优化）；
4、符合以下条件者优先：大规模推理系统经验，vLLM/SGLang开发，Tilelang/Tritton开发，深入了解Transformer架构，有量化/稀疏化等相关技术落地或者论文发表等相关经验。
