# Large Model Algorithm Researcher (Multimodal & Code AI) | 大模型算法研究员（多模态与Code AI方向）-TikTok AI创新中心-筋斗云人才计划

**ID**: 7508691509543127303
**Code**: A118205
**Location**: 新加坡
**Category**: 算法
**Type**: 正式

## 职位描述

### 团队介绍
TikTok AI创新中心，是致力于AI基础设施建设和创新研究的部门，探索行业领先的人工智能技术，包括大语言模型，多模态大模型等研究方向。我们希望研发能够处理多语言和海量视频内容理解的模型算法，为用户带来更好的内容消费体验。在Code AI方向，我们利用大语言模型强大的代码理解与推理能力，提升程序性能与研发效率。
课题介绍：
多模态基础大模型VLM 是行业的研究热点，也是TikTok业务场景应用的关键技术，2024年TikTok AI创新中心研发了面向TikTok业务场景的多模态大模型VFM V1，在公开测试集上能够与最好的开源模型 Qwen VL持平，同时在 TikTok 业务测试集上，能够大幅领先所有其它基础模型。未来，我们希望持续研发具有高效感知和推理思考能力的基础模型，能够处理多语言和海量视频内容理解的模型算法，为用户带来更好的内容消费体验。
课题挑战：

### 实习要求
Team Introduction:
The TikTok AI Innovation Center is a department focused on building AI infrastructure and driving cutting-edge research in AI. We explore industry-leading AI technologies, including large language models (LLMs) and multimodal large models, with the goal of developing models that can understand multilingual content and vast amounts of video data, ultimately delivering a better content consumption experience for users. In the Code AI domain, we leverage the powerful code understanding and reasoning capabilities of LLMs to enhance program performance and R&D efficiency.
Project Introduction:
Multimodal foundation large models (VLM) represent a research hotspot in the industry and a critical technology for TikTok's business scenario applications. In 2024, TikTok's Innovation Center developed VFM V1, a multimodal large model tailored for TikTok's business scenarios. It matches the performance of the best open-source model Qwen VL on public test sets, while significantly outperforming all other foundation models on TikTok's business test sets. In the future, we aim to continuously develop foundation models with efficient perception and reasoning capabilities, capable of handling multilingual and massive video content understanding algorithms to deliver a better content consumption experience for users.
Project Challenges:
Enhance the multimodal perception encoder: The current encoder uses a fixed frame rate. We need to explore more efficient adaptive frame rates while considering the integration of modalities such as audio and user behavior.
How to fuse multimodal perception and thinking capabilities to promote stronger comprehensive perception and cognitive abilities of the model.

### 核心工作
1、增强多模态感知编码器，当前的编码器是固定帧率，需要探索更高效的自适应帧率，同时考虑音频、用户行为等模态加入；
2、如何融合多模态感知和思考能力，促进更强的模型综合感知和认知能力。

## 职位要求
1. Got a doctor degree, with priority given to those who have published papers in fields such as machine learning (ML), computer vision (CV), and natural language processing (NLP).
2. Possess excellent programming skills, data structure, and algorithm skills, proficient in C/C++ or Python programming languages. Priority will be given to those who have won awards in competitions such as ACM/ICPC, NOI/IOI, Top Coder, and Kaggle.
3. Have research experience in the field of machine learning, particularly in large-scale language models (LLMs) and generative artificial intelligence.
4. Be passionate about technology, have outstanding problem analysis and solving abilities, be enthusiastic about solving challenging problems, and possess good communication skills and team spirit.
1、获得博士学位，在机器学习（ML）、计算机视觉（CV）、自然语言处理（NLP）等领域发布过论文者优先；
2、具备出色的编程能力、数据结构和算法技能，熟练掌握C/C++或Python编程语言，在ACM/ICPC、NOI/IOI、Top Coder、Kaggle等比赛中获奖者优先；
3、拥有机器学习领域的研究经历，特别是在大规模语言模型（LLMs）和生成式人工智能方面；
4、热爱技术，出色的问题分析和解决能力，并对解决具有挑战性的问题充满热情，良好的沟通能力和团队合作精神。
